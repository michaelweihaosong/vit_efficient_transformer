{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FeedForward_linformer' from 'linformer.linformer' (/home/mikesmac/anaconda3/envs/vit/lib/python3.8/site-packages/linformer/linformer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvit_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViT\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mperformer_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Performer\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlinformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linformer, LinformerSelfAttention, FeedForward_linformer, PreNorm\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlinformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreversible\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReversibleSequence, SequentialSequence\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnystrom_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Nystromformer, NystromAttention, FeedForward_nystromformer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FeedForward_linformer' from 'linformer.linformer' (/home/mikesmac/anaconda3/envs/vit/lib/python3.8/site-packages/linformer/linformer.py)"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from vit_pytorch.efficient import ViT as ViT_efficient\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "from performer_pytorch import Performer\n",
    "from linformer.linformer import Linformer, LinformerSelfAttention, FeedForward_linformer, PreNorm\n",
    "from linformer.reversible import ReversibleSequence, SequentialSequence\n",
    "from nystrom_attention import Nystromformer, NystromAttention, FeedForward_nystromformer\n",
    "from reformer_pytorch import Reformer\n",
    "from transformers import LongformerModel, LongformerConfig\n",
    "\n",
    "from torch import Tensor\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 101\n",
    "image_size = 256\n",
    "patch_size = 8\n",
    "d_channel = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 13289957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
       "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=192, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (transformer): Transformer(\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x ModuleList(\n",
       "        (0): Attention(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attend): Softmax(dim=-1)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): FeedForward(\n",
       "          (net): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): GELU(approximate='none')\n",
       "            (3): Dropout(p=0.0, inplace=False)\n",
       "            (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (5): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Linear(in_features=512, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViT(\n",
    "    dim = d_channel,\n",
    "    mlp_dim = d_channel,\n",
    "    image_size = image_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    depth = 8,\n",
    "    heads = 8,\n",
    "    dropout = 0.,\n",
    "    emb_dropout = 0.\n",
    ")\n",
    "print(f\"Total number of parameters in the model: {count_parameters(model)}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 13302245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
       "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=192, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Performer(\n",
       "    (net): SequentialSequence(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x ModuleList(\n",
       "          (0): PreLayerNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): SelfAttention(\n",
       "              (fast_attention): FastAttention(\n",
       "                (kernel_fn): ReLU()\n",
       "              )\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): PreLayerNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Chunk(\n",
       "              (fn): FeedForward(\n",
       "                (w1): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (w2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (proj_updater): ProjectionUpdater(\n",
       "      (instance): SequentialSequence(\n",
       "        (layers): ModuleList(\n",
       "          (0-7): 8 x ModuleList(\n",
       "            (0): PreLayerNorm(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): SelfAttention(\n",
       "                (fast_attention): FastAttention(\n",
       "                  (kernel_fn): ReLU()\n",
       "                )\n",
       "                (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): PreLayerNorm(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Chunk(\n",
       "                (fn): FeedForward(\n",
       "                  (w1): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (w2): Linear(in_features=512, out_features=512, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=512, out_features=101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = Performer(\n",
    "    dim = d_channel,\n",
    "    depth = 8,\n",
    "    heads = 8,\n",
    "    causal = False,\n",
    "    dim_head = 64,\n",
    "    ff_mult = 1,\n",
    "    generalized_attention = True,\n",
    "    kernel_fn = nn.ReLU(),\n",
    "    nb_features = 0, # if nb_features is 0, then use None as projection_matrix in generalized kernel function \\\n",
    "                                    # which means using determinisitc feature projection \\\n",
    "                                    # you need to first cd to \"~/anaconda3/envs/vit/lib/python3.8/site-packages/performer_pytorch\" \\\n",
    "                                    # edit \"performer_pytorch.py\": add \"if nb_full_blocks == 0: return None\" after Line 143\n",
    "    feature_redraw_interval = 0\n",
    ")\n",
    "\n",
    "model = ViT_efficient(\n",
    "    dim = d_channel,\n",
    "    image_size = image_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    transformer = transformer\n",
    ")\n",
    "print(f\"Total number of parameters in the model: {count_parameters(model)}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 14080997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
       "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=192, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Linformer(\n",
       "    (net): SequentialSequence(\n",
       "      (layers): ModuleList(\n",
       "        (0-7): 8 x ModuleList(\n",
       "          (0): PreNorm(\n",
       "            (fn): LinformerSelfAttention(\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_k): Linear(in_features=512, out_features=64, bias=False)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): PreNorm(\n",
       "            (fn): FeedForward(\n",
       "              (w1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (w2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "            )\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=512, out_features=101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.linformer import Linformer\n",
    "transformer = Linformer(\n",
    "    dim = d_channel,\n",
    "    seq_len = int((image_size/patch_size)**2+1),\n",
    "    depth = 8,\n",
    "    heads = 8,\n",
    "    k = 64,\n",
    "    dim_head = 64,\n",
    "    one_kv_head = True,\n",
    "    share_kv = True\n",
    "    )\n",
    "\n",
    "model = ViT_efficient(\n",
    "    dim = d_channel,\n",
    "    image_size = image_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    transformer = transformer\n",
    ")\n",
    "print(f\"Total number of parameters in the model: {count_parameters(model)}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nystromformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 13292069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
       "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=192, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Nystromformer(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): NystromAttention(\n",
       "            (to_qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (res_conv): Conv2d(8, 8, kernel_size=(33, 1), stride=(1, 1), padding=(16, 0), groups=8, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=512, out_features=101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.nystromformer import Nystromformer\n",
    "\n",
    "transformer = Nystromformer(\n",
    "        dim = d_channel,\n",
    "        dim_head = 64,\n",
    "        depth = 8,\n",
    "        heads = 8,\n",
    "        num_landmarks = 16,\n",
    "        pinv_iterations = 6\n",
    "        )\n",
    "\n",
    "model = ViT_efficient(\n",
    "    dim = d_channel,\n",
    "    image_size = image_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    transformer = transformer\n",
    ")\n",
    "print(f\"Total number of parameters in the model: {count_parameters(model)}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerModel, LongformerConfig\n",
    "from models.longformer import ViT_for_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 15403493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViT_for_longformer(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
       "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=192, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 256, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 256)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(4097, 256, padding_idx=1)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-7): 8 x LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (query_global): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key_global): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value_global): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LongformerPooler(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=512, out_features=101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = LongformerConfig(\n",
    "    attention_window=128,\n",
    "    hidden_size=int(d_channel/2),\n",
    "    num_attention_heads=8, \n",
    "    num_hidden_layers=8, \n",
    "    max_position_embeddings=4097,\n",
    "    intermediate_size=d_channel\n",
    "    )\n",
    "transformer = LongformerModel(config)\n",
    "\n",
    "model = ViT_for_longformer(\n",
    "    dim = d_channel,\n",
    "    image_size = image_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    transformer = transformer\n",
    ")\n",
    "\n",
    "print(f\"Total number of parameters in the model: {count_parameters(model)}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 11191781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViT_for_reformer(\n",
       "  (to_patch_embedding): Sequential(\n",
       "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=8, p2=8)\n",
       "    (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=192, out_features=512, bias=True)\n",
       "    (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Reformer(\n",
       "    (layers): ReversibleSequence(\n",
       "      (blocks): ModuleList(\n",
       "        (0-7): 8 x ReversibleBlock(\n",
       "          (f): Deterministic(\n",
       "            (net): PreNorm(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): LSHSelfAttention(\n",
       "                (toqk): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (tov): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (lsh_attn): LSHAttention(\n",
       "                  (dropout): Dropout(p=0, inplace=False)\n",
       "                  (dropout_for_hash): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (full_attn): FullQKAttention(\n",
       "                  (dropout): Dropout(p=0, inplace=False)\n",
       "                )\n",
       "                (post_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "                (local_attn): LocalAttention(\n",
       "                  (dropout): Dropout(p=0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (g): Deterministic(\n",
       "            (net): PreNorm(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Chunk(\n",
       "                (fn): FeedForward(\n",
       "                  (w1): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  (act): GELU(approximate='none')\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  (w2): Linear(in_features=512, out_features=512, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (irrev_blocks): ModuleList(\n",
       "        (0-7): 8 x IrreversibleBlock(\n",
       "          (f): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): LSHSelfAttention(\n",
       "              (toqk): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (tov): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (lsh_attn): LSHAttention(\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "                (dropout_for_hash): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (full_attn): FullQKAttention(\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "              (post_attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (local_attn): LocalAttention(\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (g): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Chunk(\n",
       "              (fn): FeedForward(\n",
       "                (w1): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (w2): Linear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=512, out_features=101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.reformer import ViT_for_reformer\n",
    "\n",
    "transformer = Reformer(\n",
    "    dim = d_channel,\n",
    "    depth = 8,\n",
    "    heads = 8,\n",
    "    bucket_size = 32,\n",
    "    n_hashes = 1,\n",
    "    ff_mult = 1,\n",
    "    reverse_thres = 4096,\n",
    "    lsh_dropout = 0,\n",
    "    causal = False\n",
    "    )\n",
    "\n",
    "\n",
    "model = ViT_for_reformer(\n",
    "    dim = d_channel,\n",
    "    image_size = image_size,\n",
    "    patch_size = patch_size,\n",
    "    num_classes = num_classes,\n",
    "    transformer = transformer\n",
    ")\n",
    "\n",
    "print(f\"Total number of parameters in the model: {count_parameters(model)}\")\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f1208b08c16dd1fdd28c68220ba95398a7e4f29dc958af23f85933f94df12404"
  },
  "kernelspec": {
   "display_name": "Python 3.8.18 64-bit ('vit': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6399a553d469e0ff48996abbbf709736f67989a86408514e9c9d2df62071dab6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}